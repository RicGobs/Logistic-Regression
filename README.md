# Logistic-Regression

This implementation of Logistic Regression has cost = (-y * np.log (h) - (1 - y) * np.log (1 - h)).mean ().
Of course it uses the sigmoid function and for optimization it uses the Gradient Descent.

----

Questa implementazione della Logistic Regression ha costo = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean().
Naturalmente usa la funzione sigmoid e per ottimizzazione usa il Gradient Descent.
